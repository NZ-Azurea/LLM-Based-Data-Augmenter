[
    {
        "context": "How to split a large vector into chunks in R?",
        "question": "I'm trying to split a large vector into known chunk sizes and it's slow. A solution for vectors with even remainders is here: A quick solution when a factor exists is here: Split dataframe into equal parts based on length of the dataframe I would like to handle the case of no (large) factor existing, as I would like fairly large chunks. My example for a vector much smaller than the one in my real life application: d <- 1:6510321 # Sloooow chunks <- split(d, ceiling(seq_along(d)/2000))",
        "answer": "A speed improvement from the parallel package: chunks <- parallel::splitIndices(6510321, ncl = ceiling(6510321/2000))"
    }
]